# II.5 Norms

In this lecture we discuss matrix and vector norms.

1. Vector norms: we discuss the standard $p$-norm for vectors in $â„^n$.
2. Matrix norms: we discuss how two vector norms can be used to induce a norm on matrices. These
satisfy an additional multiplicative inequality.


## 1. Vector norms

Recall the definition of a (vector-)norm:

**Definition 1 (vector-norm)** A norm $\|â‹…\|$ on a vector space $V$ (e.g. $â„^n$ or $â„‚^n$) over a field $ğ”½$ (e.g.
$â„$ or $â„‚$)  
is a function that satisfies the following, for $ğ±,ğ² âˆˆ V$ and
$c âˆˆ ğ”½$:
1. Triangle inequality: $\|ğ± + ğ² \| â‰¤ \|ğ±\| + \|ğ²\|$
2. Homogeneity: $\| c ğ± \| = |c| \| ğ± \|$
3. Positive-definiteness: $\|ğ±\| = 0$ implies that $ğ± = 0$.


Consider the following example:

**Definition 2 (p-norm)**
For $1 â‰¤ p < âˆ$ and $ğ± âˆˆ â„‚^n$, define the $p$-norm:
$$
\|ğ±\|_p := \left(\sum_{k=1}^n |x_k|^p\right)^{1/p}
$$
where $x_k$ is the $k$-th entry of $ğ±$. 
For $p = âˆ$ we define
$$
\|ğ±\|_âˆ := \max_k |x_k|
$$

**Theorem 1 (p-norm)** $\| â‹… \|_p$ is a norm for $1 â‰¤ p â‰¤ âˆ$.

**Proof**

We will only prove the case $p = 1, 2, âˆ$ as general $p$ is more involved.

Homogeneity and positive-definiteness are straightforward: e.g.,
$$
\|c ğ±\|_p = (\sum_{k=1}^n |cx_k|^p)^{1/p} = (|c|^p \sum_{k=1}^n |x_k|^p)^{1/p} = |c| \| ğ± \|
$$
and if $\| ğ± \|_p = 0$ then all $|x_k|^p$ are have to be zero.

For $p = 1,âˆ$ the triangle inequality is also straightforward:
$$
\| ğ± + ğ² \|_âˆ = \max_k (|x_k + y_k|) â‰¤Â \max_k (|x_k| + |y_k|) â‰¤ \|ğ±\|_âˆ + \|ğ²\|_âˆ
$$
and
$$
\| ğ± + ğ² \|_1 = \sum_{k=1}^n |x_k + y_k| â‰¤Â  \sum_{k=1}^n (|x_k| + |y_k|) = \| ğ± \|_1 + \| ğ²\|_1
$$

For $p = 2$ it can be proved using the Cauchyâ€“Schwartz inequality:
$$
|ğ±^â‹† ğ²| â‰¤ \| ğ± \|_2 \| ğ² \|_2
$$
That is, we have
$$
\| ğ± + ğ² \|^2 = \|ğ±\|^2 + 2 ğ±^âŠ¤ ğ² + \|ğ²\|^2 â‰¤Â \|ğ±\|^2 + 2\| ğ± \| \| ğ² \| + \|ğ²\|^2 = (\| ğ± \| +  \| ğ² \|)
$$


âˆ


 In Julia, one can use the inbuilt `norm` function to calculate norms:
 ```julia
 norm([1,-2,3]) == norm([1,-2,3], 2) == sqrt(1^2 + 2^2 + 3^2) == sqrt(14);
 norm([1,-2,3], 1) == 1 + 2 + 3 == 6;
 norm([1,-2,3], Inf) == 3;
 ```


## 2. Matrix norms
 Just like vectors, matrices have norms that measure their "length".  The simplest example is the FrÃ¶benius norm:

 **Definition 3 (FrÃ¶benius norm)** For $A âˆˆ â„‚^{m Ã— n}$ define
$$
\|A\|_F := \sqrt{\sum_{k=1}^m \sum_{j=1}^n |a_{kj}|^2}
$$

This is available as `norm` in Julia:
```julia
A = randn(5,3)
norm(A) == norm(vec(A))
```

While this is the simplest norm, it is not the most useful.  Instead, we will build a matrix norm from a 
vector norm:



**Definition 4 (matrix-norm)** Suppose $A âˆˆ â„‚^{m Ã— n}$  and consider two norms $\| â‹… \|_X$ on $â„‚^n$  and 
$\| â‹… \|_Y$ on $â„‚^n$. Define the _(induced) matrix norm_ as:
$$
\|A \|_{X â†’ Y} := \sup_{ğ¯ : \|ğ¯\|_X=1} \|A ğ¯\|_Y
$$
Also define
$$
\|A\|_X := \|A\|_{X â†’ X}
$$
For  the induced $p$-norm we use the notation $\|A\|_p.$

Note an equivalent definition of the induced norm:
$$
\|A\|_{X â†’ Y} = \sup_{ğ± âˆˆ â„^n, ğ± â‰  0} {\|A ğ±\|_Y \over \| ğ±\|_X}
$$
This follows since we can scale $ğ±$ by its norm so that it has unit norm, that is,
${ğ±} \over \|ğ±\|_X$ has unit norm.

**Lemma 1 (matrix norms are norms)** Induced matrix norms are norms, that is for $\| â‹… \| = \| â‹… \|_{X â†’ Y}$ we have:
1. Triangle inequality: $\| A + B \| â‰¤  \|A\| + \|B\|$
1. Homogeneneity: $\|c A \| = |c| \|A\|$
3. Positive-definiteness: $\|A\| =0 \Rightarrow A = 0$

In addition, they satisfy the following additional properties:
1. $\|A ğ± \|_Y â‰¤ \|A\|_{X â†’ Y} \|ğ± \|_X$
2. Multiplicative inequality: $\| AB\|_{X â†’ Z} â‰¤ \|A \|_{Y â†’ Z} \|B\|_{X â†’  Y}$

**Proof**

First we show the _triangle inequality_:
$$
\|A + B \| â‰¤ \sup_{ğ¯ : \|ğ¯\|_X=1} (\|A ğ¯\|_Y + \|B ğ¯\|_Y) â‰¤ \| A \| + \|B \|.
$$
Homogeneity is also immediate. Positive-definiteness follows from the fact that if
$\|A\| = 0$ then $A ğ±  = 0$ for all $ğ± âˆˆ â„^n$.
The property $\|A ğ± \|_Y â‰¤ \|A\|_{X â†’ Y} \|ğ± \|_X$ follows from the definition.
Finally, the multiplicative inequality follows from
$$
\|A B\| = \sup_{ğ¯ : \|ğ¯\|_X=1} \|A B ğ¯ \|_Z â‰¤Â \sup_{ğ¯ : \|ğ¯\|_X=1} \|A\|_{Y â†’ Z} \| B ğ¯ \| = \|A \|_{Y â†’ Z} \|B\|_{X â†’  Y}
$$



âˆ

We have some simple examples of induced norms:

**Example 1 ($1$-norm)** We claim 
$$
\|A \|_1 = \max_j \|ğš_j\|_1
$$
that is, the maximum $1$-norm of the columns. To see this use the triangle inequality to
find for $\|ğ±\|_1 = 1$
$$
\| A ğ± \|_1 â‰¤Â âˆ‘_{j = 1}^n |x_j| \| ğš_j\|_1 â‰¤Â \max_j \| ğš_j\| âˆ‘_{j = 1}^n |x_j| = \max_j \| ğš_j\|_1.
$$
But the bound is also attained since if $j$ is the column that maximises the norms then
$$
\|A ğ_j \|_1 = \|ğš_j\|_1 =  \max_j \| ğš_j\|_1.
$$

In the problem sheet we see that
$$
\|A\|_âˆ = \max_k \|A[k,:]\|_1
$$
that is, the maximum $1$-norm of the rows.

Matrix norms are available via `opnorm`:
```julia
m,n = 5,3
A = randn(m,n)
opnorm(A,1) == maximum(norm(A[:,j],1) for j = 1:n)
opnorm(A,Inf) == maximum(norm(A[k,:],1) for k = 1:m)
opnorm(A) # the 2-norm
```


An example that does not have a simple formula is $\|A \|_2$, but we do have two simple cases:

**Proposition 1 (diagonal/orthogonal 2-norms)** If $Î›$ is diagonal with entries $Î»_k$ then
$\|Î›\|_2 = \max_k |Î»_k|$. If $Q$ is orthogonal then $\|Q\| = 1$.

In the next chapter we see how the 2-norm for a matrix can be defined in terms of the _Singular Value Decomposition_.