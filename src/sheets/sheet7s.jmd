**Problem 5.1** For $A = U Î£ V^âŠ¤ âˆˆ â„^{m Ã— n}$ define the _pseudo-inverse_:
$$
A^+ := V Î£^{-1} U^âŠ¤.
$$
Show that it satisfies the _Moore-Penrose conditions_:
1. $A A^+ A = A$
2. $A^+ A A^+ = A^+$
3. $(A A^+)^âŠ¤  = A A^+$ and $(A^+ A)^âŠ¤ = A^+ A$

**SOLUTION**

Let $A=UÎ£ V^âŠ¤$ and $A^+ := V Î£^{-1} U^âŠ¤$, where $U âˆˆ â„^{m Ã— r}$ and $V âˆˆ â„^{n Ã— r}$. Note that $U^âŠ¤U = I_m$ and $V^âŠ¤V = I_r$. 

1. We have
$$
A A^+ A = U Î£ V^âŠ¤ V Î£^{-1} U^âŠ¤ U Î£ V^âŠ¤ = U Î£ Î£^{-1} Î£ V^âŠ¤ = UÎ£ V^âŠ¤ = A
$$
2. Moreover,
$$
A^+ A A^+ = V Î£^{-1}U^âŠ¤ U Î£ V^âŠ¤ V Î£^{-1} U^âŠ¤ = V Î£^{-1}Î£ Î£^{-1} U^âŠ¤ = V Î£^{-1} U^âŠ¤ = A^+
$$
3. 
$$
\begin{align*}
(A A^+)^âŠ¤ = (A^+)^âŠ¤ A^âŠ¤ = U Î£^{-1} V^âŠ¤ V Î£ U^âŠ¤ = U U^âŠ¤ = U Î£ V^âŠ¤ V Î£^{-1} U^âŠ¤ = A A^+ \\
(A^+ A)^âŠ¤ = A^âŠ¤ (A^+)^âŠ¤ =  V Î£ U^âŠ¤ U Î£^{-1} V^âŠ¤ = V V^âŠ¤ = V Î£^{-1} U^âŠ¤ U Î£ V^âŠ¤  = A^+ A
\end{align*}
$$


**END**

**Problem 5.2** Show for $A âˆˆ â„^{m Ã— n}$ with $m â‰¥ n$ and âŠ¤ rank
that $ğ± =  A^+ ğ›$ is the least squares solution, i.e., minimises $\| A ğ± - ğ› \|_2$.
Hint: extend $U$ in the SVD to be a square orthogonal matrix.

**SOLUTION**

The proof mimics that of the QR factorisation. Write $A =  U Î£ V^âŠ¤$ and let
$$
UÌƒ = \begin{bmatrix}U & K \end{bmatrix}
$$
so that $UÌƒ$ is orthogonal. We use the fact orthogonal matrices do not change norms:
$$
\begin{align*}
\|A ğ± - ğ› \|_2^2 &= \|U Î£ V^âŠ¤ ğ± - ğ› \|_2^2 = \|UÌƒ^âŠ¤ U Î£ V^âŠ¤ ğ± - UÌƒ^âŠ¤ ğ› \|_2^2 = \|\underbrace{\begin{bmatrix}I_m \\ O \end{bmatrix}}_{âˆˆ â„^{m Ã— n}} Î£ V^âŠ¤ ğ± - \begin{bmatrix} U^âŠ¤ \\ K^âŠ¤ \end{bmatrix} ğ› \|_2^2 \\
&= \|Î£ V^âŠ¤ ğ± - U^âŠ¤ ğ› \|_2^2 + \|K^âŠ¤ ğ›\|^2
\end{align*}
$$
The second term is independent of $ğ±$. The first term is minimised when zero:
$$
 \|Î£ V^âŠ¤ ğ± - U^âŠ¤ ğ› \|_2 =\|Î£ V^âŠ¤ V Î£^{-1} U^âŠ¤ ğ›  - U^âŠ¤ ğ› \|_2 = 0
$$

**END**

**Problem 5.3**
If $A âˆˆ â„^{m Ã— n}$ has a non-empty kernel there are multiple solutions to the least
squares problem as 
we can add any element of the kernel. Show that $ğ± = A^+ ğ›$ gives the least squares solution
such that $\| ğ± \|_2$ is minimised.

**SOLUTION**

Let $ğ±     =A^+b$ and let $ğ± + ğ¤$ to be another solution i.e.
$$
\|Ağ± - b \| = \|A (ğ± +ğ¤) - b \|
$$
Following the previous part we deduce:
$$
Î£ V^âŠ¤ (ğ± +ğ¤) = U^âŠ¤ ğ› \Rightarrow V^âŠ¤ ğ¤ = 0
$$
As $ğ± = V ğœ$ lies in the span of the columns of $V$ we have
$ğ±^âŠ¤ ğ¤ = 0$. Thus
$$
\| ğ± + ğ¤ \|^2 = \| ğ± \|^2 + \| ğ¤ \|^2
$$
which is minimised when $ğ¤ = 0$.

**END**


## 1. Condition numbers

**Problem 1.1â‹† (B)** Prove that, if $|Ïµ_i| â‰¤ Ïµ$ and $n Ïµ < 1$, then
$$
\prod_{k=1}^n (1+Ïµ_i) = 1+Î¸_n
$$
for some constant $Î¸_n$ satisfying $|Î¸_n| â‰¤ {n Ïµ \over 1-nÏµ}$.

**SOLUTION**

$$\prod_{k=1}^n(1+\epsilon_i)\le(1+\epsilon)^n=\sum_{k=0}^n {n \choose k} \epsilon^k\le 1+\sum_{k=1}^n n^k\epsilon^k\le 1+\sum_{k=1}^âˆ n^k\epsilon^k=1+\frac{n\epsilon}{1-n\epsilon}.$$
$$\prod_{k=1}^n(1+\epsilon_i)\ge(1-\epsilon)^n=\sum_{k=0}^n {n \choose k} (-\epsilon)^k\ge 1-\sum_{k=1}^n n^k\epsilon^k\ge  1-\sum_{k=1}^âˆ n^k\epsilon^k=1-\frac{n\epsilon}{1-n\epsilon}.$$

**Problem 1.2â‹† (B)** Let $A,B âˆˆ â„^{m Ã— n}$. Prove that if the columns satisfy $\|ğš_j\|_2 â‰¤Â \| ğ›_j\|_2$ then
$\|A\|_F â‰¤Â \|B\|_F$ and $\|A \|_2 â‰¤Â \sqrt{\hbox{rank}(B)} \|B\|_2$.

**SOLUTION**

Recalling from _[Problem Sheet 5](https://github.com/Imperial-MATH50003/MATH50003NumericalAnalysis/blob/main/sheets/week5s.ipynb/) - Problem 2.3* - SOLUTION_, we know that
$$\|A\|_F=\sqrt{\sum_{k,j}A[k,j]^2}=\sqrt{\sum_j\|\mathbf{a}_j\|_2^2}\qquad\text{and}\qquad\|B\|_F=\sqrt{\sum_j\|\mathbf{b}_j\|_2^2}.$$
Since $\|ğš_j\|_2 â‰¤ \| ğ›_j\|_2$, we have $\|A\|_F â‰¤ \|B\|_F$.

Recalling from _[Problem Sheet 5](https://github.com/Imperial-MATH50003/MATH50003NumericalAnalysis/blob/main/sheets/week5s.ipynb/) - Problem 3.1*_, we have
$$\|A\|_2\le\|A\|_F\le\|B\|_F\le\sqrt{\hbox{rank}(B)} \|B\|_2.$$

**Problem 1.3â‹† (C)** Compute the 1-norm, 2-norm, and âˆ-norm condition numbers for the following matrices:
$$
\begin{bmatrix}
1 & 2 \\ 3 & 4
\end{bmatrix}, \begin{bmatrix}
1/3 & 1/5 \\ 0 & 1/7
\end{bmatrix}, \begin{bmatrix} 1 \\ & 1/2 \\ && â‹¯ \\ &&& 1/2^n \end{bmatrix}
$$
(Hint: recall that the singular values of a matrix $A$ are the square roots of the eigenvalues of the Gram matrix
$A^âŠ¤A$.)

**SOLUTION**

$$
A=\begin{bmatrix}
1 & 2 \\ 3 & 4
\end{bmatrix},\qquad
A^{-1}=-\frac{1}{2}\begin{bmatrix}
4 & -2 \\ -3 & 1
\end{bmatrix}
$$

$$
B=\begin{bmatrix}
1/3 & 1/5 \\ 0 & 1/7
\end{bmatrix},\qquad
B^{-1}=21\begin{bmatrix}
1/7 & -1/5 \\ 0 & 1/3
\end{bmatrix}
$$

$\|A\|_1=6$, $\|A^{-1}\|_1=7/2$, so $\kappa_1(A)=21$.

$\|A\|_âˆ=7$, $\|A^{-1}\|_âˆ=3$, so $\kappa_âˆ(A)=21$.

$\|B\|_1=12/35$, $\|B^{-1}\|_1=21\times 8/15=56/5$, so $\kappa_1(B)=96/25$.

$\|B\|_âˆ=8/15$, $\|B^{-1}\|_âˆ=21\times 12/35$, so $\kappa_âˆ(B)=96/25$

Finally, for the $2$-norms:
$\kappa_2(A)$:
For $A = \left[\begin{matrix}
1 & 2 \\
3 & 4
\end{matrix}\right]$, we have that the singular values are the $\sigma_1 = \sqrt{\lambda_1}, \sigma_2 = \sqrt{\lambda_2}$, where $\lambda_1$ and $\lambda_2$ are the eigenvalues of $A^TA$.
$$
A^TA = \left[\begin{matrix}
10 & 14 \\
14 & 20
\end{matrix}\right],
$$
so an eigenvalue $\lambda$ of $A^TA$ must satisfy,
$$
\begin{align*}
(10 - \lambda)(20-\lambda) - 196 = 0 \\
\Leftrightarrow \lambda = 15 \pm\sqrt{221}.
\end{align*}
$$
The larger eigenvalue corresponds to $\sigma_1$, so $\sigma_1 = \sqrt{15  + \sqrt{221}}$, and the smaller corresponds to $\sigma_2$, so $\sigma_2 = \sqrt{15  - \sqrt{221}}$. Finally, we have $\|A\|_2 = \sigma_1, \|A^{-1}\|_2 = 1/\sigma_2$, and so $\kappa_2(A) = \sqrt{\frac{15  + \sqrt{221}}{15  - \sqrt{221}}}$.

 $\kappa_2(B)$:
For 
$$
B = \left[\begin{matrix}
1/3 & 1/5 \\
0 & 1/7
\end{matrix}\right],
$$
we have that the singular values are the $\sigma_1 = \sqrt{\lambda_1}, \sigma_2 = \sqrt{\lambda_2}$, where $\lambda_1$ and $\lambda_2$ are the eigenvalues of $A^TA$.
$$
A^TA = \left[\begin{matrix}
1/9 & 1/15 \\
1/15 & \frac{74}{5^27^2}
\end{matrix}\right].
$$
An eigenvalue $\lambda$ must satisfy:
\begin{align*}
(1/9 - \lambda)\left(\frac{74}{5^27^2}-\lambda\right) - \frac{1}{225} = 0 \\
\Leftrightarrow \lambda = \frac{1891 \pm29\sqrt{2941}}{22050}.
\end{align*}
With the same logic as above, we can then deduce that $$\|B\|_2 = \sqrt{\frac{1891 +29\sqrt{2941}}{22050}}$$ and $$\|B^{-1}\|_2 \sqrt{\frac{22050}{1891 -29\sqrt{2941}}}$$ so that,
$$
\kappa_2(B) = \sqrt{\frac{1891 +29\sqrt{2941}}{1891 -29\sqrt{2941}}}
$$

For,
$$
A_n = \left[\begin{matrix}1 \\ &1/2 \\&&\ddots \\&&&1/2^n \end{matrix}\right],\hspace{5mm}
A_n^{-1} = \left[\begin{matrix}1 \\ &2 \\&&\ddots \\&&&2^n \end{matrix}\right]
$$ 
It is clear that $$\|A_n\|_1 = \|A_n\|_âˆ = 1,$$ and $$\|A_n^{-1}\|_1 = \|A_n^{-1}\|_âˆ = 2^n,$$ so $\kappa_1(A_n) = \kappa_âˆ(A) = 2^n$.
Morover, we can clearly see the singular values $\sigma_1 = 1, \sigma_2 = 1/2, \dots, \sigma_{n+1} = 1/2^n$. So $\|A_n\|_2 = 1, \|A_n^{-1}\|_2 = 2^n$, $\kappa_2(A_n) = 2^n$

**Problem 1.4 (B)**
State a bound on the relative error on $A ğ¯$ for $\|ğ¯\|_2 = 1$ for the following matrices:
$$
\begin{bmatrix}
1/3 & 1/5 \\ 0 & 1/10^3
\end{bmatrix},
 \begin{bmatrix} 1 \\ & 1/2 \\ && â‹¯ \\ &&& 1/2^{10} \end{bmatrix}
$$

**SOLUTION**

The Theorem (relative-error for matrix vector) tells us that,
$$
\frac{\|\delta A \mathbf{x}\|}{\|A \mathbf{x}\|} \leq \kappa(A)\epsilon,
$$
if the relative pertubation error $\|\delta A\| = \|A\| \epsilon$. For the 2-norm, we have,
$$
\|\delta A \|_2 \leq \underbrace{\frac{\sqrt{\min(m, n)} n\epsilon_m}{2 - n\epsilon_m}}_\epsilon\|A\|_2.
$$
The condition number of the first matrix is 453.33 (see code below to compute that), and $\epsilon$ defined above is $\frac{2\sqrt{2}\epsilon_m}{2-2\epsilon_m} = 3.14 \cdot10^{-16},$ so the bound on the relative error is:
$$1.42 \cdot 10^{-13}.$$
The condition number of the second matrix is $2^{10}$ by the question above, and $\epsilon$ defined above is $\frac{10\sqrt{10}\epsilon_m}{2-10\epsilon_m} = 7.02\cdot 10^{-16},$ the bound on the relative error in this case is then:
$$
7.19\cdot 10^{-13}
$$

```julia
using LinearAlgebra

A = [1/3 1/5; 0 1/1000]
U,Ïƒ,V = svd(A)
Îº = Ïƒ[1]/Ïƒ[end]
v = V[:,end]
``` 
```julia
A_big = [big(1)/3 big(1)/5; 0 big(1)/1000]
``` 
```julia
norm(A_big*v - A*v, 2)/norm(A_big*v, 2)
``` 
```julia
2*sqrt(2)*eps()/(2-2*eps())* Îº
``` 
```julia
B = diagm( 2.0 .^(0:-1:-10))
U,Ïƒ,V = svd(B)
Îº = Ïƒ[1]/Ïƒ[end]
v = V[:,end]
``` 
```julia
B*v
``` 

Note, this is exact so the relative error is 0, within the upper bound.
```julia
10*sqrt(10)*eps()/(10-10*eps()) * 2^(10)
``` 

