# MATH50003 Numerical Analysis (2022â€“23)
# Problem Sheet 10


This problem sheet explores interpolation with Lagrange polynomials, interpolatory quadrature,
orthogonal polynomial roots and Gaussian quadrature.



----


**Problem 1** Use Lagrange interpolation to
interpolate the function $\cos x$ by a polynomial at the points
$[0,2,3,4]$ and evaluate at $x = 1$. 

**SOLUTION**

- $â„“_0(x)=\frac{(x-2)(x-3)(x-4)}{(0-2)(0-3)(0-4)}=-\frac{1}{24}(x-2)(x-3)(x-4)$
- $â„“_2(x)=\frac{(x-0)(x-3)(x-4)}{(2-0)(2-3)(2-4)}=\frac{1}{4}x(x-3)(x-4)$
- $â„“_3(x)=\frac{(x-0)(x-2)(x-4)}{(3-0)(3-2)(3-4)}=-\frac{1}{3}x(x-2)(x-4)$
- $â„“_4(x)=\frac{(x-0)(x-2)(x-3)}{(4-0)(4-2)(4-3)}=\frac{1}{8}x(x-2)(x-3)$

$p(x)=\cos(0)â„“_0(x)+\cos(2)â„“_2(x)+\cos(3)â„“_3(x)+\cos(4)â„“_4(x)$

$â„“_0(1)=1/4$, $â„“_2(1)=3/2$, $â„“_3(1)=-1$, $â„“_4(1)=1/4$, so $p(1)=1/4\cos(0)+3/2\cos(2)-\cos(3)+1/4\cos(4)$.

```julia
using Plots
l0(x)=-1/24*(x-2)*(x-3)*(x-4)
l2(x)=1/4*x*(x-3)*(x-4)
l3(x)=-1/3*x*(x-2)*(x-4)
l4(x)=1/8*x*(x-2)*(x-3)
p(x)=cos(0)*l0(x)+cos(2)*l2(x)+cos(3)*l3(x)+cos(4)*l4(x)

plot([p cos], xlims=(-1,5))
```

**END**

----


**Problem 2.1** What are the upper 3x3 sub-block of the Jacobi matrix for the 
monic and orthonormal polynomials with respect to the following weights on
$[-1,1]$:
$$
1-x, \sqrt{1-x^2}, 1-x^2
$$

**SOLUTION**

#### Monic

We know that for monic ($b_n=1$) orthogonal polynomials we can write the upper 3x3 block in the form

$$X_3 = \begin{bmatrix} a_0 & c_0 & 0 \\ 1 & a_1 & c_1 \\ 0 & 1 & a_2 \end{bmatrix}$$


1. $w(x) = 1-x$

Take $Ï€_0(x) = 1$ (monic) and note
$$
\| Ï€_0 \|^2 = \int_{-1}^1 (1-x) {\rm d}x = 2
$$
From
$$
xÏ€_0(x) = a_0Ï€_0(x) + Ï€_1(x)
$$
we deduce
$$
a_0 = âŸ¨x Ï€_0, Ï€_0âŸ©/\|Ï€_0\|^2 =  {\int_{-1}^1 (1-x) x {\rm d}x \over 2} =  -{1 \over 3}
$$
i.e.
$$
Ï€_1(x) = (x-a_0) Ï€_0(x) = x + 1/3.
$$
and note that
$$
\|Ï€_1\|^2 = \int_{-1}^1 (1-x) (x+1/3)^2 {\rm d} x = 4/9.
$$
From
$$
xÏ€_1(x) = c_0 Ï€_0(x) + a_1 Ï€_1(x) + Ï€_2(x)
$$
we deduce
$$
c_0 = âŸ¨x Ï€_1, Ï€_0âŸ©/\|Ï€_0\|^2 =  {\int_{-1}^1 (1-x) x (x+1/3) {\rm d}x \over 2} =  {2 \over 9}
$$
and
$$
a_1 = âŸ¨x Ï€_1, Ï€_1âŸ©/\|Ï€_1\|^2 =  {9 \over 4} {\int_{-1}^1 (1-x) x (x+1/3)^2 {\rm d}x} =  -{1 \over 15}
$$
Thus
$$
Ï€_2(x) = (x - a_1) Ï€_1(x) - c_0 Ï€_0(x) = (x+1/15) (x+1/3) - 2/9 = x^2 + 2x/5 -1/5.
$$
And once again as before:
$$
c_1=\frac{âŸ¨ Ï€_1, xÏ€_2âŸ©}{\|Ï€_1\|^2}= \frac{\int_{-1}^1 (x+\frac{1}{3})(x^2+\frac{2}{5}x- \frac{1}{5}) x(1-x) dx}{\int_{-1}^1 (x+\frac{1}{3})^2 (1-x) dx}= \frac{6}{25}$$
and
$$
a_2 = \frac{âŸ¨ Ï€_2, xÏ€_2âŸ©}{\|Ï€_2\|^2} = \frac{\int_{-1}^1 (x^2+\frac{2}{5}x- \frac{1}{5})^2 x(1-x) dx}{\int_{-1}^1 (x^2+\frac{2}{5}x- \frac{1}{5})^2 (1-x) dx}= -\frac{1}{35}
$$
Thus we have
$$
X_3 = \begin{bmatrix}
-1/3 & 2/9 \\
1 & -1/15 & 6/25 \\
& 1 & -1/35
\end{bmatrix}
$$

2. $w(x)=\sqrt{1-x^2}$

Take $Ï€_0(x) = k_0 = 1$ (monic) so that
$$
\|Ï€_0\|^2 = \int_{-1}^1 \sqrt{1-x^2} = {Ï€ \over 2}.
$$
From PS8, Problem 3.4 we know that $a_k = 0$. Thus
from the recurrence we have
$$
xÏ€_0(x) =  Ï€_1(x)
$$
and hence
$$
Ï€_1(x) = x Ï€_0(x) = x.
$$
Likewise for
$$
xÏ€_1(x)= c_0Ï€_0(x)+Ï€_2(x)
$$
we have
$$
c_0=\frac{âŸ¨ Ï€_0, xÏ€_1âŸ©}{\|Ï€_0\|^2} \frac{\int_{-1}^1 x^2\sqrt{1-x^2} dx}{Ï€/2}=\frac{Ï€/8}{Ï€/2}= \frac{1}{4}
$$
i.e.
$$
Ï€_2(x) = xÏ€_1(x) - c_0 = x^2 - {1 \over 4}.
$$
Finally:
$$
xÏ€_2(x)= c_1Ï€_1(x)Ï€_3(x)
$$
and thus
$$
c_1=\frac{âŸ¨ Ï€_1, xÏ€_2âŸ©}{\|Ï€_1\|^2}= \frac{\int_{-1}^1 (x^2- \frac{1}{4}) x^2\sqrt{1-x^2} dx}{\int_{-1}^1 x^2 \sqrt{1-x^2} dx}= \frac{Ï€/32}{Ï€/8}=\frac{1}{4}
$$

Thus we have
$$
X_3 = \begin{bmatrix}
0 & 1/4 \\
1 & 0 & 1/4 \\
& 1 & 0
\end{bmatrix}
$$

3. $w(x)=1-x^2$

Take $Ï€_0(x) = k_0 = 1$ (monic). Again due to $w(x) = w(-x)$
from recurrence we have
$$
xÏ€_0(x) = Ï€_1(x)
$$
Then from
$$xÏ€_1(x)= c_0Ï€_0(x)+Ï€_2(x)$$
we find
$$c_0=\frac{âŸ¨ Ï€_0, xÏ€_1âŸ©}{\|Ï€_0\|^2} \frac{\int_{-1}^1 x^2(1-x^2) dx}{4/15}=\frac{4/15}{4/3}= \frac{1}{5}$$
Finally,
$$xÏ€_2(x)= c_1Ï€_1(x)+Ï€_3(x)$$
and thus
$$c_1=\frac{âŸ¨ Ï€_1, xÏ€_2âŸ©}{\|Ï€_1\|^2}= \frac{\int_{-1}^1 (x^2- \frac{1}{5}) x^2(1-x^2) dx}{\int_{-1}^1 x^2 (1-x^2) dx}= \frac{32/525}{4/15}=\frac{8}{35}$$
Thus we have
$$
X_3 = \begin{bmatrix}
0 & 1/5 \\
1 & 0 & 8/35 \\
& 1 & 0
\end{bmatrix}
$$

#### Orthonormal

The hard way to solve this problem is to compute $\|Ï€_n\|$ for each case.
Instead, we use a trick for computing the orthonormal  variants: III.3 Corollary 6 tells us that if we find constants $Î±_n$ and define
$$
q_n(x) := Î±_n Ï€_n(x)
$$
so that $\|q_0\| = 1$ and the resulting Jacobi matrix is symmetric then $q_n$ must be orthonormal.
Note that the three-term recurrence for $q_n$ satisfies
$$
\begin{align*}
x q_0 = x Î±_0 Ï€_0 = Î±_0 a_0 Ï€_0 + Î±_0 Ï€_1 = a_0 q_0 + {Î±_0 \over Î±_1} q_1 \\
x q_m = x Î±_n Ï€_n = Î±_n c_{n-1} Ï€_{n-1} +  a_n Î±_n Ï€_n + Î±_n Ï€_{n+1} = {Î±_n c_{n-1} \over Î±_{n-1}}  q_{n-1} + a_n q_n + {Î±_n \over Î±_{n+1}} q_{n+1}
\end{align*}
$$
This is easier to see using linear algebra:
$$
\begin{align*}
x [q_0 | q_1 | â€¦ ] &= x[Ï€_0 | Ï€_1 | â€¦] \begin{bmatrix} Î±_0 \\ & Î±_1 \\ && â‹± \end{bmatrix} = [Ï€_0 | Ï€_1 | â€¦] X \begin{bmatrix} Î±_0 \\ & Î±_1 \\ && â‹± \end{bmatrix}   \\
&=[q_0 | q_1 | â€¦] \begin{bmatrix} Î±_0^{-1} \\ & Î±_1^{-1} \\ && â‹± \end{bmatrix}  X \begin{bmatrix} Î±_0 \\ & Î±_1 \\ && â‹± \end{bmatrix} \\
&=[q_0 | q_1 | â€¦] \underbrace{\begin{bmatrix}  a_0 & c_0 Î±_1/Î±_0 \\
									Î±_0/Î±_1 & a_1 & c_1 Î±_2/Î±_1 \\
									& Î±_1/Î±_2 & a_2 & â‹± \\
									&& â‹± & â‹±
									\end{bmatrix}}_{XÌƒ}
\end{align*}
$$
Thus to make this symmetric we need $ cÌƒ_n := c_n Î±_{n+1}/Î±_n = Î±_n/Î±_{n+1} =: bÌƒ_n$, i.e., $Î±_{n+1} = Î±_n/\sqrt{c_n}$,
in other words,
$$
Î±_n = {Î±_0 \over âˆ_{k=0}^{n-1} \sqrt{c_k}}.
$$
Moreover, we see with this choice that $cÌƒ_n = \sqrt{b_n} = \sqrt{c_n}$ 

1. $w(x) = 1-x$. We know $q_0(x) = Î±_0 = 1/\|Ï€_0\| = 1/\sqrt{2}$. Then $Î±_1 = 1/\sqrt{2c_0} =3/2$ (hence $q_1(x) = Î±_1 Ï€_1(x) = 3x/2+ 1/2$),
which tells us
$$
cÌƒ_0 = c_0 Î±_1/Î±_0 = \sqrt{2}/3 = bÌƒ_0 (= \sqrt{c_0}.)
$$
Then $Î±_2 = Î±_1/\sqrt{c_1} = 15/(2\sqrt{6})$ which tells us $cÌƒ_1 = c_1 Î±_2/Î±_1 = \sqrt{6}/5 = bÌƒ_1 (= \sqrt{c_1})$. In other words we have,
$$
XÌƒ_3 = \begin{bmatrix}
-1/3 & \sqrt{2}/3 \\
 \sqrt{2}/3 & -1/15 & \sqrt{6}/5 \\
& \sqrt{6}/5 & -1/35
\end{bmatrix}
$$

2. $w(x) = \sqrt{1-x^2}$ We can just jump ahead since we know the answer is just with $\sqrt{c_n}$ in place of $b_n$ and $c_n$:
$$
XÌƒ_3 = \begin{bmatrix}
0 & 1/2 \\
1/2 & 0 & 1/2 \\
& 1/2 & 0
\end{bmatrix}
$$

3. $w(x) = 1-x^2$:
$$
XÌƒ_3 = \begin{bmatrix}
0 & 1/\sqrt{5} \\
1/\sqrt{5} & 0 & \sqrt{8/35} \\
& \sqrt{8/35} & 0
\end{bmatrix}
$$

**END**


**Problem 2.2** Compute the roots of the Legendre polynomial $P_3(x)$, orthogonal with respect
to $w(x) = 1$ on $[-1,1]$, by computing the eigenvalues of a $3 Ã— 3$ truncation
of the Jacobi matrix.

**SOLUTION**

We have, $P_0(x) = 1$. Though recall that in order to use Lemma (zeros), the Jacobi matrix must be symmetric and hence the polynomials orthonormal. So Take $Q_0(x) = 1/||P_0(x)|| = \frac{1}{\sqrt{2}}$. Then we have, by the three term recurrence relationship,
$$
xQ_0(x) = a_0Q_0(x) + b_0Q_1(x),
$$
and taking the inner product of both sides with $Q_0(x)$ we get, 
$$a_0 = âŸ¨ xQ_0(x), Q_0(x) âŸ© = \int_{-1}^1 x/2 dx = 0.$$
Next recall that $P_1(x) =  x$ and so $Q_1(x) = x/||P_1(x)||=\sqrt{\frac{3}{2}} x$. We then have, taking the innner product of the first equation above with $Q_ 1(x)$,
$$
b_0 = âŸ¨ xQ_0(x), Q_1(x)âŸ© = \int_{-1}^1 \frac{\sqrt{3}}{2}x^2 dx = \frac{1}{\sqrt{3}},
$$
and also $b_0 = c_0$ by the Corollary (orthonormal 3-term recurrence). We have,
$$
a_1 = âŸ¨ xQ_1(x), Q_1(x)âŸ© = \int_{-1}^1 \frac{3}{2}x^3 dx = 0.
$$
Recall that $P_2(x) = \frac{1}{2}(3x^2 - 1)$, so that $Q_2(x) = P_2(x)/||P_2(x)|| = \sqrt{\frac{5}{8}}(3x^2 - 1)$, and that,
$$
xQ_1(x) = c_0Q_0(x) + a_1Q_1(x) + b_1Q_2(x).
$$
Taking inner the inner product of both sides with $Q_2(x)$, we see that,
$$
c_1 = b_1 = âŸ¨ xQ_1(x), Q_2(x)âŸ© = \int_{-1}^1 \sqrt{\frac{5}{8}} \cdot \sqrt{\frac{3}{2}}(3x^2 - 1)\cdot x \cdot xdx =\frac{2}{\sqrt{15}}.
$$
Finally,
$$
a_2 = âŸ¨ Q_2(x), xQ_2(x) âŸ© = \frac{5}{8}\int_{-1}^1 (3x^2 - 1)^2 x dx = 0.
$$
This gives us the truncated Jacobi matrix,
$$
X_3 = \left[\begin{matrix}
a_0 & b_0	& 0 \\
b_0 & a_1 & b_1 \\
0&b_1 & a_2
\end{matrix}
 \right] = \left[\begin{matrix}
0 & \frac{1}{\sqrt{3}}	& 0 \\
\frac{1}{\sqrt{3}} & 0 & \frac{2}{\sqrt{15}} \\
0& \frac{2}{\sqrt{15}} & 0
\end{matrix}
 \right],
$$
whose eigenvalues are the zeros of $Q_3(x)$, and hence the zeros of $P_3(x)$ since they are the same up to a constant. To work out the eigenvalues, we have,
$$
\begin{align*}
	|X_3 - \lambda I| = \left| \begin{matrix}
		-\lambda & \frac{1}{\sqrt{3}} & 0\\ 
		\frac{1}{\sqrt{3}} & -\lambda & \frac{2}{\sqrt{15}}\\
		0 & \frac{2}{\sqrt{15}} & -\lambda 
	\end{matrix}\right| &= 0 \\
	\Leftrightarrow -\lambda(\lambda^2 - \frac{4}{15}) - \frac{1}{\sqrt{3}}\cdot \frac{-\lambda}{\sqrt{3}} &=0 \\
	\Leftrightarrow -\lambda^3 + \frac{3}{5}\lambda &= 0,
\end{align*}
$$
which has solutions $\lambda = 0, Â± \sqrt{\frac{3}{5}}$

**END**

-----


**Problem 3.1** Compute the interpolatory quadrature rule for
$w(x) = \sqrt{1-x^2}$ with the points $[-1,1/2,1]$.

**SOLUTION**

For the points $ð± = \{-1, 1/2, 1\}$ we have the Lagrange polynomials:
$$
â„“_1(x) = \left(\frac{x - 1/2}{-1 - 1/2}\right)\cdot\left(\frac{x - 1}{-1 - 1}\right) = \frac{1}{3}\left(x^2 - \frac{3}{2}x + \frac{1}{2}\right),
$$
and
$$
â„“_2(x) = -\frac{4}{3}x^2 + \frac{4}{3}, â„“_3(x) =x^2 + \frac{1}{2}x - \frac{1}{2},
$$
similarly. We can then compute the weights,
$$
w_j = \int_{-1}^1 â„“_j(x)w(x)dx,
$$
using,
$$
\int_{-1}^1 x^k \sqrt{1-x^2}dx = \begin{cases}
 \frac{Ï€}{2} &	k=0 \\
 0 & k=1 \\
\frac{Ï€}{8} & k=2
 \end{cases}
$$
to find,
$$
w_j = \begin{cases}
 	\frac{Ï€}{8} & j = 1 \\
 	\frac{Ï€}{2} & j = 2 \\
 	-\frac{Ï€}{8} & j = 3,
 \end{cases}
$$
so that the interpolatory quadrature rule is:
$$
Î£_3^{w,ð±}(f) = \frac{Ï€}{2}\left(\frac{1}{4}f(-1) + f(1/2) -\frac{1}{4}f(1) \right)
$$

**END**

**Problem 3.2** Compute the 2-point 
interpolatory quadrature rule associated with roots of orthogonal polynomials for the weights $\sqrt{1-x^2}$, $1$, 
and $1-x$ on $[-1,1]$ by integrating the Lagrange bases.

**SOLUTION**
For $w(x) = \sqrt{1-x}^2$ the orthogonal polynomial of degree 2 is $U_2(x) = 4x^2 -1$, with roots $ð± = \{x = Â± \frac{1}{2}\}$. The Lagrange polynomials corresponding to these roots are,
\begin{align*}
â„“_1(x) &= \frac{x - 1/2}{-1/2 - 1/2} = \frac{1}{2} - x, \\
â„“_2(x) &= \frac{x + 1/2}{1/2 + 1/2} = x + \frac{1}{2}
\end{align*}
We again work out the weights
$$
w_j = \int_{-1}^1 â„“_j(x)w(x)dx,
$$
to find,
$$
w_1 = w_2 = {Ï€ \over 4},
$$
and thus the interpolatory quadrature rule is,
$$
Î£_2^{w,ð±}(f) = \frac{Ï€}{4}(f(-1/2) + f(1/2)).
$$

For $w(x) = 1$, the orthogonal polynomial of degree 2 is, using Legendre Rodriguez formula:
$$
P_2(x) = \frac{1}{(-2)^22!} \frac{d^2}{dx^2}\left(1 - x^2\right)^2 = -\frac{1}{2} + \frac{3}{2}x^2.
$$
This has roots $ð± = \left\{Â± \frac{1}{\sqrt{3}}\right\}$. We then have,
\begin{align*}
	â„“_1(x) &= -\frac{\sqrt{3}}{2}x + \frac{1}{2} \\
	â„“_2(x) &= \frac{3}{2}x + \frac{1}{2},
\end{align*}
from which we can compute the weights,
$$
w_1 = w_2 = 1,
$$
which give the quadrature rule:
$$
Î£_2^{w,ð±}(f) = \left[f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right)\right]
$$

Finally, with $w(x) = 1 - x$ we use the solution to PS9 Problem 1.1, which states that
$$
p_2(x) = x^2 + 2x/5 - 1/5
$$
which has roots, $ð± = \left\{-\frac{1}{5} Â± \frac{\sqrt{6}}{5} \right\}$. The Lagrange polynomials are then,
\begin{align*}
	â„“_1(x) &= \frac{x - (-\frac{1}{5} + \frac{\sqrt{6}}{5} )}{-\frac{1}{5} - \frac{\sqrt{6}}{5} - (-\frac{1}{5} + \frac{\sqrt{6}}{5}) } \\
	&= \frac{x - (-\frac{1}{5} + \frac{\sqrt{6}}{5} )}{-\frac{2\sqrt{6}}{5}} \\
	&=-\frac{5}{2\sqrt{6}}x - \frac{1}{2\sqrt{6}} + \frac{1}{2} \\
	â„“_2(x) &= \frac{x - (-\frac{1}{5} - \frac{\sqrt{6}}{5} )}{\frac{2\sqrt{6}}{5}} \\
	&= \frac{5}{2\sqrt{6}}x + \frac{1}{2\sqrt{6}} + \frac{1}{2}
\end{align*}
From which we can compute the weights,
\begin{align*}
	w_1 &= 1 + \frac{\sqrt{6}}{9}, \\
	w_2 &= 1 - \frac{\sqrt{6}}{9},
\end{align*}
giving the quadrature rule,
$$
Î£_2^{w,ð±}(f) = \left[\left(1 + \frac{\sqrt{6}}{9} \right)f\left(-\frac{1}{5} - \frac{\sqrt{6}}{5} \right) + \left(1 - \frac{\sqrt{6}}{9} \right)f\left(-\frac{1}{5} + \frac{\sqrt{6}}{5} \right) \right]
$$
**END**



**Problem 3.2** Compute the 2-point and 3-point Gaussian quadrature rules associated with $w(x) = 1$ on $[-1,1]$. 

**SOLUTION**

For the weights $w(x) = 1$, the orthogonal polynomials of degree $â‰¤ 3$ are the Legendre polynomials,
\begin{align*}
	P_0(x) = 1, \\
	P_1(x) = x, \\
	P_2(x) = \frac{1}{2}(3x^2  - 1), \\
	P_3(x) = \frac{1}{2}(5x^3 - 3x)
\end{align*}
which can be found from, e.g, the Rodriguez formula or by direct construction. 
We can normalise each to get $q_j(x) = P_j(x)/\|P_j\|$, with $\|P_j\|^2 = \int_{-1}^1 P_j^2 dx$. This gives,
\begin{align*}
	q_0(x) = \frac{1}{\sqrt{2}}, \\
	q_1(x) = \sqrt{\frac{3}{2}}x, \\
	q_2(x) = \sqrt{\frac{5}{8}}(3x^2  - 1), \\
	q_3(x) = \sqrt{\frac{7}{8}}(5x^3 - 3x).
\end{align*}
For the first part we use the roots of $P_2(x)$ which are $ð± = \left\{Â± \frac{1}{\sqrt{3}}\right\}$. The weights are,
$$
w_j = \frac{1}{Î±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2} = \frac{1}{\frac{1}{2}+\frac{3}{2}x_j^2},
$$
where $Î±_j$ is the same as in III.6 Lemma 2,
so that,
$$
w_1 = w_2 = 1,
$$
and the Gaussian Quadrature rule is,
$$
Î£_2^w[f] = f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right)
$$
For the second part, we use the roots of $P_3(x)$ which are $ð± = \left\{0, Â± \sqrt{\frac{3}{5}} \right\}$. The weights are then,
$$
w_j = \frac{1}{Î±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2 + q_2(x_j)^2} = \frac{1}{\frac{9}{8} -\frac{9}{4}x_j^2 + \frac{45}{8}x_j^4 }
$$
Giving us,
$$
\begin{align*}
	w_1 = w_3 = \frac{1}{\frac{9}{8} - \frac{9}{4}\frac{3}{5} + \frac{45}{8}\frac{9}{25}} &= \frac{5}{9} \\
	w_2 &= \frac{8}{9}
\end{align*}
$$
Then the Gaussian Quadrature rule is,
$$
Î£_3^w[f] = \frac{1}{9} \left[5f\left(-\sqrt\frac{3}{5}\right) +8f(0) + 5f\left(\sqrt\frac{3}{5}\right) \right]
$$

**END**

-----


**Problem 4.1** Give an explicit diagonalisation of
$$
X_n = \begin{bmatrix} 0 & 1/2 \\ 
                1/2 & 0 & â‹±  \\
                & â‹± & â‹± & 1/2 \\
                && 1/2 & 0
                \end{bmatrix} âˆˆ â„^{n Ã— n}
$$
for all $n$ by relating it to the Jacobi matrix for $U_n(x)$.

**SOLUTION**

Recall the three term recurrence for the Chebyshev Polynomials $U_n$,
$$
\begin{align*}
	xU_0(x) &= \frac{1}{2} U_1(x), \\
	xU_n(x) &= \frac{U_{n-1}(x)}{2} + \frac{U_{n+1}(x)}{2},
\end{align*}
$$
and hence, we can see that,
$$
X_n = \left[\begin{matrix}
	0 & 1/2 \\
	1/2 & 0 & \ddots \\
	&\ddots & \ddots & 1/2 \\ 
	&&1/2 & 0
\end{matrix} \right],
$$
is the $n \times n$ truncation of the Jacobi matrix. If $x_1,\dots, x_n$ are the zeros of $U_n(x)$, by Lemma (zeros) we have that,
$$
X_nQ_n = Q_n \left[\begin{matrix}
x_1 \\
&x_2 \\
&&\ddots \\
&&&x_n	
\end{matrix}
 \right],
$$
for,
$$
Q_n = \left[\begin{matrix}
	U_0(x_1) & \cdots & U_0(x_n) \\
	\vdots & \ddots & \vdots \\
	U_{n-1}(x_1) & \cdots & U_{n-1}(x_n)
\end{matrix} \right] DÌƒ = QÌƒ_n DÌƒ
$$
where
$$
DÌƒ = \begin{bmatrix} 1/\sqrt{U_0(x_1) + â‹¯ + U_{n-1}(x_1)} \\ &â‹± \\ 1/\sqrt{U_0(x_n) + â‹¯ + U_{n-1}(x_n)}
\end{bmatrix}
$$
guarantess that $Q_n$ is orthogonal.
Recall that if $x = \cos Î¸$ then $U_n(x) = \frac{\sin(n+1)Î¸}{\sin Î¸}$, 
so in particular the roots of $U_n(x)$ are 
$x_k = \cos\left(\frac{kÏ€}{n+1} \right)$ for $k = 1,\dots,n$, 
(where $\sin \left(\frac{kÏ€}{n+1}\right) â‰  0$). Hence, we have,
$$
\begin{align*}
	X_n &= Q_n\left[\begin{matrix}
x_1 \\
&x_2 \\
&&\ddots \\
&&&x_n	
\end{matrix}
 \right]Q_n^âŠ¤ \\
 &= QÌƒ_n DÌƒ \left[\begin{matrix}
x_1 \\
&x_2 \\
&&\ddots \\
&&&x_n	
\end{matrix}
 \right] DÌƒ^{-1}QÌƒ_n^{-1} \\
 &= QÌƒ_n\left[\begin{matrix}
x_1 \\
&x_2 \\
&&\ddots \\
&&&x_n	
\end{matrix}
 \right] DÌƒ DÌƒ^{-1}QÌƒ_n^{-1} \\
 &=QÌƒ_n\left[\begin{matrix}
\cos\left(\frac{Ï€}{n+1}\right) \\
&\cos\left(\frac{2Ï€}{n+1}\right) \\
&&\ddots \\
&&&\cos\left(\frac{nÏ€}{n+1}\right)
\end{matrix}
 \right]QÌƒ_n^{-1} \\
 &= QÌƒ_nÎ›_nQÌƒ_n^{-1},
\end{align*} 
$$
where, 
$$
QÌƒ_n = \left[\begin{matrix}
	1 & \cdots & 1\\
	\frac{\sin\left(2\cdot \frac{2Ï€}{n+1} \right)}{\sin\left(\frac{2Ï€}{n+1}\right)} & \cdots & \frac{\sin\left(2\cdot \frac{nÏ€}{n+1} \right)}{\sin\left(\frac{nÏ€}{n+1}\right)} \\
	\vdots & & \vdots \\
	\frac{\sin\left(n\cdot \frac{2Ï€}{n+1} \right)}{\sin\left(\frac{2Ï€}{n+1}\right)} & \cdots & \frac{\sin\left( n\cdot \frac{nÏ€}{n+1} \right)}{\sin\left(\frac{nÏ€}{n+1}\right)}
\end{matrix} \right],
$$
and,
$$
Î›_n = \left[\begin{matrix}
\cos\left(\frac{Ï€}{n+1}\right) \\
&\cos\left(\frac{2Ï€}{n+1}\right) \\
&&\ddots \\
&&&\cos\left(\frac{nÏ€}{n+1}\right)
\end{matrix}
 \right]
$$

**END**


**Problem 4.2â‹†** Show for $w(x) = 1/\sqrt{1-x^2}$ that the Gaussian quadrature rule is
$$
Q_n^w[f] = {Ï€ \over n} \sum_{j=1}^n f(x_j)
$$
where $x_j = \cos(Î¸_j)$ for $Î¸_j = (j-1/2)Ï€/n$.

**SOLUTION**

For $w(x) = \frac{1}{\sqrt{1-x^2}}$, the orthogonal polynomials are the Chebyshev polynomials $T_n(x) = \cos(n\arccos(x))$. To make them orthonormal, we have,
\begin{align*}
	q_0(x) &= \frac{1}{\sqrt{Ï€}}, \\
	q_n(x) &= \frac{2}{Ï€}\cos(n\arccos(x)), \hspace{5mm} (n > 0)
\end{align*}
We have,
\begin{align*}
	q_n(x) = 0 &\Leftrightarrow \cos(n\arccos(x)) = 0 \\
	&\Leftrightarrow n\arccos(x) = jÏ€ - \frac{Ï€}{2}, \hspace{5mm} (j \in \mathbb{Z}) \\
	&\Leftrightarrow x = \cos\left(\frac{(j-\frac{1}{2})Ï€}{n} \right), \hspace{5mm} (j \in \mathbb{Z}),
\end{align*}
which has unique solutions $\left\{x_j = \cos\left(\frac{(j-\frac{1}{2})Ï€}{n} \right) : j = 1, \dots, n\right\}$. We then have,
$$
w_j = \frac{1}{Î±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2 + \dots q_{n-1}(x_j)^2}
$$
Consider, writing $ Î¸_j = \frac{(j-\frac{1}{2})Ï€}{n} $
\begin{align*}
	Î±_j^2 &= \sum_{k=0}^{n-1}q_k(x_j)^2 \\
	&= \frac{1}{Ï€} + \frac{2}{Ï€}\sum_{k=1}^{n-1}\cos^2(k Î¸_j) \\
	&= \frac{1}{Ï€} + \frac{1}{2Ï€}\sum_{k=1}^{n-1}(e^{ik Î¸_j} + e^{-ik Î¸_j})^2 \\
	&= \frac{1}{Ï€} + \frac{1}{2Ï€} \sum_{k=1}^{n-1}( e^{2ik Î¸_j} + e^{-2ik Î¸_j} + 2) \\
	&= \frac{n}{Ï€} + \frac{1}{2Ï€} \sum_{k=1}^{n-1}(e^{2ik Î¸_j} + e^{-2ik Î¸_j})
\end{align*}
Using a geometric sum (in essentially the same way as the solution of Problem 1.2 in Problem Sheet 8) we can show that the second term is 0 and thus $w_j = \frac{1}{Î±_j^2} = \frac{Ï€}{n}$.

**END**


**Problem 4.3â‹†** Solve Problem 4.2 from PS8 using **Lemma III.6.3 (discrete orthogonality)** with
$w(x) = 1/\sqrt{1-x^2}$ on $[-1,1]$. That is, use the connection of $T_n(x)$ with $\cos n Î¸$ to
show that the Discrete Cosine Transform
$$
C_n := \begin{bmatrix}
\sqrt{1/n} \\
 & \sqrt{2/n} \\ 
 && â‹± \\
 &&& \sqrt{2/n}
 \end{bmatrix}
\begin{bmatrix}
    1 & â‹¯ & 1\\
    \cos Î¸_1 & â‹¯ & \cos Î¸_n \\
    â‹® & â‹± & â‹® \\
    \cos (n-1)Î¸_1 & â‹¯ & \cos (n-1)Î¸_n
\end{bmatrix}
$$
for $Î¸_j = Ï€(j-1/2)/n$ is an orthogonal matrix.

**SOLUTION**


By the Lemma 3 (Discrete Orthogonality), we have,
\begin{align*}
	Î£_{n}^w[q_lq_m] = \frac{Ï€}{n}\sum_{j=1}^n q_l(x_j)q_m(x_j) = Î´_{lm}, \\
	\sum_{j=1}^n q_l(x_j)q_m(x_j) = \frac{n}{Ï€}Î´_{lm},
\end{align*}
By the previous question, for the weight $w(x) = \frac{1}{\sqrt{1-x^2}}$ we have $q_0(x_j) = \frac{1}{\sqrt{Ï€}}$, $q_k(x_j) = \sqrt{\frac{2}{Ï€}}\cos(k Î¸_j).$
For $l = m = 0$ then we have,
\begin{align*}
	\frac{1}{Ï€}\sum_{j=1}^n \cos(l Î¸_j)\cos(m Î¸_j) =\sum_{j=1}^nq_l(x_j)q_m(x_j) =  \frac{n}{Ï€}Î´_{lm} = \frac{n}{Ï€} \\
	\Rightarrow \frac{1}{n}\sum_{j=1}^n \cos(l Î¸_j)\cos(m Î¸_j) = 1\
\end{align*}
Now, for $l = m â‰  0$, we have,
\begin{align*}
	\frac{2}{Ï€}\sum_{j=1}^n \cos(l Î¸_j)\cos(m Î¸_j) =\sum_{j=1}^nq_l(x_j)q_m(x_j) =  \frac{n}{Ï€}Î´_{lm} = \frac{n}{Ï€} \\
	\Rightarrow \frac{1}{n}\sum_{j=1}^n \cos(l Î¸_j)\cos(m Î¸_j) = \frac{1}{2}\
\end{align*}
Finally, for $l â‰  m$, we have,
$$
C_{lm}\sum_{j=1}^n\cos(l Î¸_j)\cos(m Î¸_j) = \sum_{j=1}^nq_l(x_j )q_m(x_j) = \frac{n}{Ï€}Î´_{lm} = 0,
$$
for some constant $C_{lm} â‰  0$ which is $\frac{1}{Ï€}$ if $l = 0$ or $m = 0$ and $\frac{2}{Ï€}$ otherwise (it doesn't matter what it is so long as it is not 0). Therefore, for $l â‰  m$ we have,
$$
\frac{1}{n}\sum_{j=1}^n \cos(l Î¸_j)\cos(m Î¸_j) = 0
$$

**END**



-----